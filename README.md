# ğŸ¦¾ Prosthetic Hand Gesture Controller

A real-time hand tracking simulation that demonstrates the core principles behind modern neuroprosthetics and brain-computer interfaces. Track your hand movements via webcam and watch them mirrored on a robotic prosthetic visualization â€” no hardware required.

ğŸ”— **[Live Demo](https://prosthetic-hand-controller.vercel.app)**

![Demo Screenshot](demo.png)

## âœ¨ Features

- **Real-time Hand Tracking** â€” MediaPipe Hands for accurate 21-point landmark detection
- **Prosthetic Visualization** â€” Metallic robotic hand with glowing LED-style joints
- **Skeleton Mode** â€” Toggle to see raw landmark connections
- **Gesture Recognition** â€” Detects 6 gestures:
  - âœŠ Fist
  - ğŸ–ï¸ Open Palm
  - ğŸ‘† Pointing
  - âœŒï¸ Peace
  - ğŸ‘ Thumbs Up
  - ğŸ¤ Pinch
- **Left & Right Hand Support** â€” Works with both hands
- **Mirrored Display** â€” Natural interaction like a mirror
- **Zero Setup** â€” Runs entirely in the browser

## ğŸ§  How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Webcam    â”‚ â†’   â”‚  MediaPipe  â”‚ â†’   â”‚   Canvas    â”‚
â”‚   Input     â”‚     â”‚  Hand Track â”‚     â”‚  Rendering  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    21 hand landmarks
                    (x, y, z coordinates)
                           â†“
                    Gesture Detection
                           â†“
                    Visual Feedback
```

This project demonstrates key concepts used in real prosthetic systems:

| Real Prosthetics | This Simulation |
|------------------|-----------------|
| EMG sensors read muscle signals | Camera captures hand movements |
| Signal processing algorithms | MediaPipe ML model |
| Motor controllers | Canvas rendering |
| Servo motors | Visual prosthetic hand |

## ğŸ› ï¸ Tech Stack

- **MediaPipe Hands** â€” Hand landmark detection
- **Canvas API** â€” Real-time rendering
- **Tailwind CSS** â€” Styling
- **Vanilla JavaScript** â€” No frameworks needed

## ğŸš€ Quick Start

### Option 1: Use Live Demo
Visit **[prosthetic-hand-controller.vercel.app](https://prosthetic-hand-controller.vercel.app)**

### Option 2: Run Locally
1. Download `index.html`
2. Open in Chrome or Edge
3. Allow camera access
4. Show your hand!

## ğŸ“ Project Structure

```
prosthetic-hand-controller/
â”œâ”€â”€ index.html    â† Single file application
â””â”€â”€ README.md     â† Documentation
```

## ğŸ“ Educational Value

This project is useful for:

- **Biomedical Engineering Students** â€” Understanding human-machine interfaces
- **Rehabilitation Research** â€” Demonstrating prosthetic concepts
- **Patient Education** â€” Showing how modern prosthetics work
- **STEM Outreach** â€” Engaging demonstrations

## ğŸ”® Future Enhancements

- [ ] 3D WebGL hand model with Three.js
- [ ] More gesture types (grip patterns)
- [ ] Grip strength visualization
- [ ] Two-hand tracking
- [ ] EMG sensor integration (Arduino)
- [ ] VR/AR compatibility

## ğŸ“š References

- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [Hand Landmark Model Paper](https://arxiv.org/abs/2006.10214)
- [Prosthetic Control Systems](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6068572/)

## ğŸ‘¨â€ğŸ’» Author

**Mohammad Khalaf**  
Biomedical Engineering Student | IÅŸÄ±k University

- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/mohammad-khalaf-b80273261)
- ğŸ™ [GitHub](https://github.com/mohammadkhalaf)

---

*Built as part of my biomedical engineering portfolio â€” demonstrating the intersection of computer vision, AI, and healthcare technology.*
